{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# COGS 118A - Project Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Names\n",
    "\n",
    "- Raam Chaklashiya\n",
    "- Vinay Pillai\n",
    "- Juan Villalobos\n",
    "- Kavya Balaji\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Abstract \n",
    "\n",
    "Diabetes is a chronic health condition which affects approximately 422 million adults worldwide, with the majority of those affected living in low\\-income or underdeveloped countries. The timely diagnosis and treatment of diabetes can be crucial to patient health; access to insulin and health monitoring can be the difference between life and death. Our project aims to develop a binary classifier for diabetes based on the Diabetes Prediction Dataset from Kaggle; it provides multiple variables such as age, smoking history, blood measurements, and the presence of related conditions like hypertension and heart disease, of which we will be identifying the most significant features that contribute to diabetes. We aim to build the classifier using a random forest technique and validate our model using a train/validation/test split. We also plan to use grid search to optimize hyperparameters and measure our model's accuracy using recall and F1\\-Score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Background\n",
    "\n",
    "Diabetes is a chronic, metabolic disease which has the potential to cause serious organ damage to the heart, blood vessels, eyes, and more. Type 2 diabetes is most common in adults, which we have seen rising prevalence of in recent years. Type 2 diabetes occurs when the body becomes resistant to insulin, and Type 1 diabetes occurs when the body does not produce enough insulin[\\[1\\]](#lorenznote). Both forms of diabetes require timely diagnosis and treatment, which is why building models to potentially identify diabetes based on various metrics is an important and necessary pursuit. In doing so, we may be able to diagnose individuals who carry markers or fit trends earlier than before.\n",
    "\n",
    "Currently, identifying diabetes has to do with symptoms, not markers for disease. Type 1 diabetes can cause nausea, vomiting, or stomach pains; however, symptoms of Type 2 diabetes can take years to develop, and may never[\\[2\\]](#admonishnote)! So, predicting the disease without seeing symptoms has the potential to save lives. Progress has been made in terms of using machine learning to identify diabetes and other forms of disease. Logistic regression, random forest, a developed ensemble model, and SVM were all methods considered in a study by BMC Medical [\\[3\\]](#admonishnote). The developed ensemble model received an AU\\-ROC score of 73.7, which was the best performance without laboratory data. Similar studies have been conducted by the NIH and BioMed Central, showing that there is sure progress to be made in this realm. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Problem Statement\n",
    "\n",
    "We aim to identify relevant risk factors associated with diabetes and predict whether or not a patient has diabetes based on health factors such as age, related medical conditions such as hypertension and heart disease, and blood measurements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data\n",
    "\n",
    "The dataset we will be using to accomplish our project is the [Diabetes Prediction Dataset](https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset) from Kaggle, sourced from the Electronic Health Records \\(EHRs\\). It contains 100,000 observations of 9 variables. An observation consists of one entry of each of the following nine variables: gender, age, hypertension, heart disease, smoking history, BMI, HbA1c level \\(Hemoglobin A1c\\), blood glucose level, and diabetes. Some of the critical variables are hypertension, heart disease, and diabetes, which are represented by a 0 or 1 to indicate the presence of the condition. Additionally, smoking history, BMI, HbA1c level, and blood glucose level are critical since they are common risk factors for diabetes. Smoking history is represented by one of 6 categories which we will use one\\-hot encoding to represent: not current, former, no info, current, never, and ever. We will filter out the observations with no info of smoking history to provide our model with more consistent data which will leave us with around 64,000 observations. BMI and HbA1c level are represented as whole number or decimal value, while blood glucose level is represented entirely by whole numbers.\n",
    "\n",
    "After importing our data, we first removed all data points that didn't have smoking history information as shown below, which left us with 64,184 data points.\n",
    "\n",
    "![](.Checkpoint_Group034-SP23.ipynb.upload/paste-0.5720741359320756)\n",
    "\n",
    "Next, we one\\-hot encoded the smoking history categories so that we could use them as predictors for our model. \n",
    "\n",
    "![](.Checkpoint_Group034-SP23.ipynb.upload/paste-0.7226018210828424)\n",
    "\n",
    "Finally, we dropped the old smoking history column and joined our dataframe with the one\\-hot encoding.\n",
    "\n",
    "![](.Checkpoint_Group034-SP23.ipynb.upload/paste-0.16279488800394892)\n",
    "\n",
    "We used a similar approach to one\\-hot encode the gender variable and after cleaning our data, we have 64,184 observations of 13 variables, 12 of which we will use as predictors to predict the 13th variable, the presence of diabetes. Smoking history is now represented as a one\\-hot encoding of 5 levels: current, ever, former, never, and not current, with a 1 indicating the smoking status and 0s in the other 4 positions for a given observation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Proposed Solution\n",
    "\n",
    "Since we are working on a binary classification task \\(whether or not a patient has diabetes\\), a reasonable classifier to use is a random forest, which has numerous advantages in the context of our dataset. Random forests are fast to train even on large datasets like ours and still retain good performance. They also can give an estimate as to which features are more significant in classification via permutation, which is important to know since we are trying to identify the most significant risk factors of diabetes. Furthermore, by the nature of using decision trees for classification, we won't have to scale our variables to match each other which could have been a concern since HbA1c level is on a much lower scale than blood glucose level and BMI. \n",
    "\n",
    "We will use a train/validation/test split to test our model since we have a lot of data. After initially training the random forest, we will use grid search to find the best hyperparameters for our model on the validation set. Finally, we will test our model on the test set and evaluate its performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "A valid evaluation metric for our problem would be recall, which is defined as the number of true positives divided by the number of true positives \\+ false negatives. We are most concerned with correctly identifying the presence of diabetes \\(true positive\\) and minimizing the number of times our model incorrectly identifies a patient with diabetes as not having diabetes \\(false negative\\), which is exactly what recall measures. However, it is also important to consider false positives, since theoretically a model could simply predict all patients as having diabetes and this would maximize recall but would have an over\\-abundance of false positives. For this reason, we will also be looking at the F1\\-score of our model as it takes into account precision and recall and gives us an idea of the overall accuracy of our model. Precision is defined as the number of true positives divided by the number of true positives \\+ false positives and F1\\-score is: $\\dfrac{2\\times Precision \\times Recall}{Precision+Recall}$ .\n",
    "\n"
   ]
  },
  {
   "attachments": {
    "4.png": {
     "image/png": "PNGIHDRsRGBgAMAapHYsodIDATxy57GMDcM0QXitPzDU6Xgw+8r2s9s3s00J00aaTbJs3BHr90BJNvcZcGCSa1a9sja00iK/aaO00R00aaJ00aaT0PaQ00BaFR00aaJ00SZ/dtlf9TYkMmMa9w5oEvsXhll3VziZ+SA/IzRk/oryXrnoqhJ0axwzYzjoTolsrnTm+wc51WRpYlhJLtbQZilyquqYf+gw/T3J+7jtd5hucRp7iy5pre82Zevcrunf4wSpvNpDk7l6e7oylZ95/4KgB3cy5jgBS/Z/5kryyZhj3VZUNmar"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preliminary results\n",
    "\n",
    "For our initial approach, we worked with the 'clean' data \\(one\\-hot encoding for all categorical variable except gender, which was encoded with the LabelEncoder\\). We then performed a 75/25 train/test split and utilized the random forest classifier from sklearn. We used a grid search to optimize our hyper\\-parameters, working with a search space of 4 possible values for the number of estimators of the random forest classifier. The grid search used 5\\-fold cross validation and used the F1\\-score to grade each hyper\\-parameter set.\n",
    "![4.png](imgs/4.PNG)\n",
    "\n",
    "From the confusion matrix above, we can see that the model tends to correctly classify true negatives very accurately with a specificity of $\\frac{14158}{14158+81}=99.43\\%$, meaning we classify non\\-diabetic patients as non\\-diabetic 99.43% of the time. However, we are mainly concerned with recall which is $\\frac{1261}{1261+546}=69.78\\%$ for this model, meaning we classify diabetic patients as diabetic only 69.78% of the time, which is far from ideal. The precision of this model is $\\frac{1261}{1261+81}=93.96\\%$ which indicates that 93.96% of our model's diabetic predictions were correct. Putting these facts together, we can notice that this model tends to miss a lot of patients who are diabetic and misclassify them as non\\-diabetic rather than classifying non\\-diabetics as diabetic. The F1\\-score for this model was 80% which doesn't sound too bad, however since we are more concerned with the recall of the model, we would like to improve it while still maintaining a high level of overall accuracy/F1\\-score. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "When looking at data a major concern is the privacy of individuals: not allowing the public to be able to identify the person based on the information from this data.  Another concern would be that of consent: where the data that was collected was obtained forcefully from the patient. Our data was from Kaggle, where the person who obtained the data got it from various healthcare providers, such as hospitals and clinics. The patients allowed these healthcare providers to obtain this information from different tests. From these places they have a set of procedures that they need to follow in order for them to get consent form the patients. When it comes to the privacy of the individuals, the data that was collected do not have specific enough information to make an individual known to the public therefore we can safely say that their privacy is secured. \n",
    "\n",
    "Another aspect that can be of concern is that of collection bias: where the data that was collected from a specific set of individuals that may be prone to what we are investigating or not be prone to, based on the methods of the data collection. A way this has been overcome was through the methods of how the data was collected from different electronic health records from different hospitals and clinics, therefore minimizing the amount of data that was collected specifically from individuals that may be prone to what we are investigating or not be prone to. Therefore our predictions from this dataset should not be exposed from collection bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The majority of the collaborative work will be done on CoCalc \\(for Jupyter notebooks\\) and Google Docs. The team will primarily use Discord to handle project discussions and to schedule meetings periodically. In these meetings, we will assess project progress, discuss any issues that have arisen, establish deadlines, and allocate work for each teammate. Work allocations will be flexible, and each person will be able to claim the sections they want to work on. Any conflicts regarding work allocations or project issues will be handled on Discord, and team members will be expected to be responsive, handle their claimed sections by any discussed deadlines, and help each other as needed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "| Meeting Date | Meeting Time | Completed Before Meeting | Discuss at Meeting |\n",
    "| :----------- | :------------- | :----------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| 5/17 \\(W\\) | 4 PM | Brainstorm topics/questions \\(all\\) | Determine best form of communication; Discuss and decide on final project topic; assign proposal sections. COMPLETED. |\n",
    "| 5/22 \\(M\\) | 4 PM | Do background research on topic | Discuss ideal dataset\\(s\\) and ethics; draft project proposal. COMPLETED. |\n",
    "| 5/24 \\(W\\) | 4 PM | Read TA/Instructor feedback on Proposal, Peer Review | Discuss proposal feedback and how to fix any incorrect sections; Assign group members to lead project tasks. NOTE: we skipped this meeting, and instead reviewed proposal feedback at 5/29 meeting. |\n",
    "| 5/29 \\(M\\) | 4 PM | Import & Wrangle Data, do some EDA | Review/Edit wrangling/EDA; Discuss Analysis Plan. COMPLETED. |\n",
    "| 5/31 \\(W\\) | 4 PM | Project Checkpoint | Discuss and finalize project checkpoint before submission. At this point in the project, we have a modeling approach completed as well as a visualization of the results. COMPLETED. |\n",
    "| 6/7 \\(W\\) | 4 PM | Attempt model selection and training | Check\\-in on Final Project progress and discuss any issues/changes |\n",
    "| 6/14 \\(W\\) | Before 8:00 PM | Finalize Final Report, complete team evaluation survey | Turn in Final Project |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Footnotes\n",
    "\n",
    "1.[^](#lorenz)World Health Org. \\[[https://www.who.int/health\\-topics/diabetes\\#tab=tab\\_1](https://www.who.int/health-topics/diabetes#tab=tab_1) \\]<br> \n",
    "2.[^C](#admonish)DC https://www.cdc.gov/diabetes/basics/symptoms.html <br>\n",
    "3.[^BMC: ](#sota): [https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911\\-019\\-0918\\-5](https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-019-0918-5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel",
    "--HistoryManager.enabled=False",
    "--matplotlib=inline",
    "-c",
    "%config InlineBackend.figure_formats = set(['retina'])\nimport matplotlib; matplotlib.rcParams['figure.figsize'] = (12, 7)",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (system-wide)",
   "env": {
   },
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}